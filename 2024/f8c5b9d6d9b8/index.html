<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Fire-Flyer AI-HPC: A Cost-Effective Software-Hardware Co-Design for Deep Learning</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  <style>
    body { 
      font-family: 'Inter', sans-serif; 
      scroll-behavior: smooth;
    }
    .mobile-optimized { 
      margin-bottom: 2rem !important; 
    }
    @media (max-width: 768px) {
      .content-section { 
        padding: 1rem; 
        margin-bottom: 1.5rem;
      }
      .technical-details {
        margin: 1rem 0;
      }
    }
    .hide-scrollbar {
      -ms-overflow-style: none;
      scrollbar-width: none;
    }
    .hide-scrollbar::-webkit-scrollbar {
      display: none;
    }
    .nav-item {
      @apply px-4 py-2 rounded-lg transition-colors duration-200 text-gray-600 hover:text-blue-600 hover:bg-blue-50;
    }
    .nav-item.active {
      @apply text-blue-600 bg-blue-100;
    }
  </style>
</head>
<body class="bg-gradient-to-br from-blue-400 via-purple-500 to-pink-400 min-h-screen">
  <!-- 导航系统 -->
  <nav class="nav-scroll bg-white/90 backdrop-blur-sm sticky top-0 z-50 border-b border-gray-200">
    <div class="container mx-auto px-4 py-3">
      <div class="flex overflow-x-auto space-x-6 hide-scrollbar">
        <a href="#abstract" class="nav-item whitespace-nowrap">摘要</a>
        <a href="#background-motivation" class="nav-item whitespace-nowrap">背景与动机</a>
        <a href="#challenges" class="nav-item whitespace-nowrap">问题与挑战</a>
        <a href="#design-implementation" class="nav-item whitespace-nowrap">设计与实现</a>
        <a href="#evaluation" class="nav-item whitespace-nowrap">测试与评估</a>
        <a href="#conclusion" class="nav-item whitespace-nowrap">结论</a>
      </div>
    </div>
  </nav>

  <div class="container mx-auto px-4 py-8">
    <div class="bg-white/95 backdrop-blur-sm rounded-xl shadow-lg p-6">
      <!-- 论文标题和元数据 -->
      <div class="mb-12 md:mb-16">
        <h1 class="text-3xl md:text-4xl font-bold text-gray-800 mb-6 text-center md:text-left">
          Fire-Flyer AI-HPC: A Cost-Effective Software-Hardware Co-Design for Deep Learning
        </h1>
        
        <div class="bg-gradient-to-r from-blue-50 to-purple-50 border-l-4 border-blue-500 p-6 rounded-r-lg">
          <div class="grid grid-cols-1 md:grid-cols-2 gap-4 text-gray-700">
            <div class="space-y-3">
              <div>
                <strong class="text-blue-700 block mb-1">作者信息</strong>
                <div class="text-lg">Wei An, Xiao Bi, Guanting Chen, Shanhuang Chen, Chengqi Deng, Honghui Ding, Kai Dong, Qiushi Du, Wenjun Gao, Kang Guan, Jianzhong Guo, Yongqiang Guo, Zhe Fu, Ying He, Panpan Huang, Jiashi Li, Wenfeng Liang, Xiaodong Liu, Xin Liu, Yiyuan Liu, Yuxuan Liu, Shanghao Lu, Xuan Lu, Xiaotao Nie, Tian Pei, Junjie Qiu, Hui Qu, Zehui Ren, Zhangli Sha, Xuecheng Su, Xiaowen Sun, Yixuan Tan, Minghui Tang, Shiyu Wang, Yaohui Wang, Yongji Wang, Ziwei Xie, Yiliang Xiong, Yanhong Xu, Shengfeng Ye, Shuiping Yu, Yukun Zha, Liyue Zhang*, Haowei Zhang, Mingchuan Zhang, Wentao Zhang, Yichao Zhang, Chenggang Zhao, Yao Zhao, Shangyan Zhou, Shunfeng Zhou, Yuheng Zou</div>
                <div class="text-sm text-gray-600 mt-1">DeepSeek-AI, Beijing, China</div>
              </div>
            </div>
            <div class="space-y-3">
              <div>
                <strong class="text-blue-700 block mb-1">关键词</strong>
                <div class="flex flex-wrap gap-2 mt-1">
                  <span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm">High Performance Computing</span>
                  <span class="bg-green-100 text-green-800 px-3 py-1 rounded-full text-sm">Cost-Effective</span>
                  <span class="bg-purple-100 text-purple-800 px-3 py-1 rounded-full text-sm">All-Reduce</span>
                  <span class="bg-yellow-100 text-yellow-800 px-3 py-1 rounded-full text-sm">Deep Learning</span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
      
      <!-- 核心贡献突出显示 -->
      <div class="bg-gradient-to-r from-green-50 to-blue-50 border-l-4 border-green-500 p-6 rounded-r-lg mb-12">
        <h4 class="font-bold text-green-700 mb-4 flex items-center text-xl">
          <i class="fas fa-trophy mr-2"></i>核心贡献
        </h4>
        <ul class="list-disc list-inside space-y-2 text-gray-700">
          <li><strong>Fire-Flyer 2 AI-HPC架构</strong>：部署了10,000个PCIe A100 GPU的集群，性能接近DGX-A100，但成本降低一半，能耗降低40%</li>
          <li><strong>IFFReduce通信库</strong>：通过CPU异步allreduce实现计算通信重叠，在PCIe架构上优于NCCL</li>
          <li><strong>计算存储一体化网络</strong>：采用双层Fat-Tree拓扑，实现存储和计算网络的集成</li>
          <li><strong>全面软件栈</strong>：包括HaiScale、3FS分布式文件系统和HAI平台，实现高可扩展性和稳定性</li>
        </ul>
      </div>
      
      <!-- 摘要 -->
      <section id="abstract" class="content-section mobile-optimized mb-12 md:mb-16">
        <h2 class="text-2xl md:text-3xl font-bold text-gray-800 mb-6 md:mb-8 flex items-center">
          <i class="fas fa-file-alt mr-3 text-blue-500"></i>
          摘要
        </h2>
        <div class="prose max-w-none text-gray-700">
          <p class="mb-4">深度学习和大型语言模型的快速发展显著增加了对计算能力和带宽的需求。结合更快的计算芯片和互连技术的高成本，这显著提高了高性能计算系统的建设成本。</p>
          <p class="mb-4">为了应对这些挑战，作者引入了Fire-Flyer AI-HPC架构，这是一种协同的硬件-软件协同设计框架及其最佳实践。对于深度学习训练，作者部署了包含10,000个PCIe A100 GPU的Fire-Flyer 2集群，实现了接近DGX-A100的性能，同时将成本降低一半，能耗降低40%。</p>
          <p>作者特别设计了IFFReduce来加速allreduce通信，并实施了多项措施以保持计算存储一体化网络无拥塞。通过软件栈，包括HaiScale、3FS和HAI-Platform，作者通过重叠计算和通信实现了显著的可扩展性。从深度学习训练中获得的系统导向经验为AI-HPC的未来发展提供了宝贵的见解。</p>
        </div>
      </section>
      
      <!-- 背景与动机 -->
      <section id="background-motivation" class="content-section mobile-optimized mb-12 md:mb-16">
        <h2 class="text-2xl md:text-3xl font-bold text-gray-800 mb-6 md:mb-8 flex items-center">
          <i class="fas fa-layer-group mr-3 text-blue-500"></i>
          背景与动机
        </h2>
        
        <div class="prose max-w-none text-gray-700">
          <p class="mb-4">近年来，深度学习迅速发展并广泛应用于图像识别、语音识别、内容生成、自动驾驶等领域。深度学习的快速发展从根本上与数据的支持有关。使用大量数据进行训练需要大规模计算资源。</p>
          <p class="mb-6">虽然依赖摩尔定律，计算机速度平均每两年翻一番，但深度学习的发展速度远远超过这个速度。特别是近年来流行的大型语言模型对计算资源和内存的需求呈爆炸式增长。LLM的参数可以达到数百亿到数千亿，需要数百或数千个GPU进行训练。</p>
          
          <!-- 深度学习计算能力指数增长图 -->
          <details class="technical-details bg-gray-50 rounded-lg p-4 md:p-6 mb-8">
            <summary class="cursor-pointer font-semibold text-lg md:text-xl text-gray-800 hover:text-blue-600 transition-colors py-2">
              <i class="fas fa-chart-line mr-2"></i>技术细节：图1 - 深度学习计算能力的指数增长
            </summary>
            
            <div class="mt-6 space-y-6">
              <!-- 原图展示部分 -->
              <div class="original-figure-container">
                <div class="flex flex-col sm:flex-row sm:items-center justify-between mb-4 gap-2">
                  <h5 class="font-semibold text-gray-700 text-base md:text-lg">
                    <i class="fas fa-image mr-2 text-blue-500"></i>
                    原图 1: 深度学习计算能力的指数增长
                  </h5>
                  <span class="text-xs bg-blue-100 text-blue-800 px-2 py-1 rounded self-start sm:self-auto">论文原图</span>
                </div>
                
                <!-- 原图占位符 -->
                <div class="image-placeholder bg-gradient-to-br from-gray-100 to-gray-200 p-6 md:p-8 rounded-lg text-center border-2 border-dashed border-gray-300">
                  <img src="./images/fig1.png" alt="论文图1: 深度学习计算能力的指数增长" class="max-w-full h-auto rounded-lg">
                </div>
                
                <!-- 原图图注 -->
                <div class="mt-4 text-sm text-gray-600 bg-gray-50 p-3 rounded border">
                  <strong>原图图注:</strong> 深度学习计算能力的指数增长趋势图
                </div>
              </div>
              
              <!-- 技术解释部分 -->
              <div class="bg-blue-50 p-4 rounded-lg border border-blue-200">
                <h5 class="font-semibold text-blue-700 mb-3 flex items-center text-base md:text-lg">
                  <i class="fas fa-info-circle mr-2"></i>技术解释：
                </h5>
                <ul class="list-disc list-inside space-y-2 text-sm md:text-base text-gray-700">
                  <li><strong>指数增长趋势:</strong> 深度学习对计算能力的需求呈指数级增长，远超传统硬件发展速度</li>
                  <li><strong>AI与硬件差距:</strong> AI对计算能力的需求每年增长10倍，而摩尔定律仅每两年增长3倍</li>
                  <li><strong>内存带宽挑战:</strong> DRAM带宽每两年仅增长1.6倍，互连带宽仅增长1.4倍</li>
                  <li><strong>成本影响:</strong> 这种差距导致需要更多机器，显著增加了深度学习训练成本</li>
                </ul>
              </div>
            </div>
          </details>
          
          <p class="mb-4">虽然LLM训练具有挑战性，但更多参数带来的新兴能力显示了持续模型扩展的好处。此后，研究人员走上了使模型更大的道路，并且再也没有回头。为了获得更多计算资源，人们不得不扩展更多节点。这导致构建AI基础设施的成本激增。</p>
          
          <div class="bg-yellow-50 border-l-4 border-yellow-500 p-4 rounded-r-lg mb-6">
            <h5 class="font-bold text-yellow-700 mb-2 flex items-center">
              <i class="fas fa-exclamation-triangle mr-2"></i>关键挑战
            </h5>
            <ul class="list-disc list-inside text-gray-700">
              <li>如何降低新数据中心的建设成本</li>
              <li>如何构建成本效益高的集群</li>
              <li>更多节点导致更高的能耗，与减少碳排放和实现碳中和的时代目标相矛盾</li>
            </ul>
          </div>
        </div>
      </section>
      
      <!-- 问题与挑战 -->
      <section id="challenges" class="content-section mobile-optimized mb-12 md:mb-16">
        <h2 class="text-2xl md:text-3xl font-bold text-gray-800 mb-6 md:mb-8 flex items-center">
          <i class="fas fa-exclamation-triangle mr-3 text-blue-500"></i>
          问题与挑战
        </h2>
        
        <div class="prose max-w-none text-gray-700">
          <h3 class="text-xl font-bold text-gray-800 mb-4">深度学习训练中的挑战</h3>
          
          <div class="grid grid-cols-1 md:grid-cols-2 gap-6 mb-8">
            <div class="bg-red-50 p-4 rounded-lg border border-red-200">
              <h4 class="font-bold text-red-700 mb-3 flex items-center">
                <i class="fas fa-tachometer-alt mr-2"></i>效率挑战
              </h4>
              <ul class="list-disc list-inside space-y-2 text-gray-700">
                <li>大规模训练的效率至关重要</li>
                <li>模型FLOPs利用率(MFU)是评估训练效率的标准指标</li>
                <li>通信、操作优化、数据预处理和GPU内存消耗显著影响MFU</li>
              </ul>
            </div>
            
            <div class="bg-orange-50 p-4 rounded-lg border border-orange-200">
              <h4 class="font-bold text-orange-700 mb-3 flex items-center">
                <i class="fas fa-shield-alt mr-2"></i>稳定性挑战
              </h4>
              <ul class="list-disc list-inside space-y-2 text-gray-700">
                <li>大规模训练的高稳定性至关重要</li>
                <li>训练具有万亿token的大模型可能持续数周</li>
                <li>慢节点和硬件故障是常见现象而非异常</li>
                <li>稳定性直接影响任务恢复时间</li>
              </ul>
            </div>
          </div>
          
          <h3 class="text-xl font-bold text-gray-800 mb-4">并行策略</h3>
          
          <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4 mb-8">
            <div class="tech-card bg-blue-50 p-4 rounded-lg border border-blue-200">
              <h4 class="font-bold text-blue-700 text-base md:text-lg mb-2">
                <i class="fa-solid fa-copy mr-2"></i>数据并行
              </h4>
              <p class="text-sm text-gray-700">模型和优化器状态在多个设备上复制，数据均匀分布到所有设备</p>
            </div>
            
            <div class="tech-card bg-green-50 p-4 rounded-lg border border-green-200">
              <h4 class="font-bold text-green-700 text-base md:text-lg mb-2">
                <i class="fa-solid fa-code-branch mr-2"></i>流水线并行
              </h4>
              <p class="text-sm text-gray-700">每个设备持有部分模型层，训练批次划分为微批次进行流水线执行</p>
            </div>
            
            <div class="tech-card bg-purple-50 p-4 rounded-lg border border-purple-200">
              <h4 class="font-bold text-purple-700 text-base md:text-lg mb-2">
                <i class="fa-solid fa-cube mr-2"></i>张量并行
              </h4>
              <p class="text-sm text-gray-700">模型层放置在多个GPU上，并行执行计算</p>
            </div>
            
            <div class="tech-card bg-yellow-50 p-4 rounded-lg border border-yellow-200">
              <h4 class="font-bold text-yellow-700 text-base md:text-lg mb-2">
                <i class="fa-solid fa-user-friends mr-2"></i>专家并行
              </h4>
              <p class="text-sm text-gray-700">MoE模型的不同专家模型分布在不同的GPU上</p>
            </div>
            
            <div class="tech-card bg-indigo-50 p-4 rounded-lg border border-indigo-200">
              <h4 class="font-bold text-indigo-700 text-base md:text-lg mb-2">
                <i class="fa-solid fa-puzzle-piece mr-2"></i>全分片数据并行
              </h4>
              <p class="text-sm text-gray-700">基于ZeRO Stage-3算法，分区模型参数、优化器状态和梯度</p>
            </div>
          </div>
          
          <!-- 硬件能力与需求差距图 -->
          <details class="technical-details bg-gray-50 rounded-lg p-4 md:p-6 mb-8">
            <summary class="cursor-pointer font-semibold text-lg md:text-xl text-gray-800 hover:text-blue-600 transition-colors py-2">
              <i class="fas fa-chart-bar mr-2"></i>技术细节：图2 - 峰值硬件FLOPS和内存/互连带宽的扩展
            </summary>
            
            <div class="mt-6 space-y-6">
              <!-- 原图展示部分 -->
              <div class="original-figure-container">
                <div class="flex flex-col sm:flex-row sm:items-center justify-between mb-4 gap-2">
                  <h5 class="font-semibold text-gray-700 text-base md:text-lg">
                    <i class="fas fa-image mr-2 text-blue-500"></i>
                    原图 2: 峰值硬件FLOPS和内存/互连带宽的扩展
                  </h5>
                  <span class="text-xs bg-blue-100 text-blue-800 px-2 py-1 rounded self-start sm:self-auto">论文原图</span>
                </div>
                
                <!-- 原图占位符 -->
                <div class="image-placeholder bg-gradient-to-br from-gray-100 to-gray-200 p-6 md:p-8 rounded-lg text-center border-2 border-dashed border-gray-300">
                  <img src="./images/fig2.png" alt="论文图2: 峰值硬件FLOPS和内存/互连带宽的扩展" class="max-w-full h-auto rounded-lg">
                </div>
                
                <!-- 原图图注 -->
                <div class="mt-4 text-sm text-gray-600 bg-gray-50 p-3 rounded border">
                  <strong>原图图注:</strong> AI对计算能力的需求每年增长10倍，而硬件FLOPs每两年仅增长3.0倍，DRAM带宽增长1.6倍，互连带宽增长1.4倍
                </div>
              </div>
              
              <!-- 技术解释部分 -->
              <div class="bg-blue-50 p-4 rounded-lg border border-blue-200">
                <h5 class="font-semibold text-blue-700 mb-3 flex items-center text-base md:text-lg">
                  <i class="fas fa-info-circle mr-2"></i>技术解释：
                </h5>
                <ul class="list-disc list-inside space-y-2 text-sm md:text-base text-gray-700">
                  <li><strong>AI需求增长:</strong> AI对计算能力的需求每年增长10倍，远超硬件发展速度</li>
                  <li><strong>硬件FLOPs增长:</strong> 硬件峰值FLOPS每两年仅增长3.0倍</li>
                  <li><strong>内存带宽限制:</strong> DRAM带宽每两年仅增长1.6倍</li>
                  <li><strong>互连带宽瓶颈:</strong> 互连带宽每两年仅增长1.4倍</li>
                  <li><strong>系统影响:</strong> 这种差距导致需要更多机器，显著增加了深度学习训练成本</li>
                </ul>
              </div>
            </div>
          </details>
        </div>
      </section>
      
      <!-- 设计与实现 -->
      <section id="design-implementation" class="content-section mobile-optimized mb-12 md:mb-16">
        <h2 class="text-2xl md:text-3xl font-bold text-gray-800 mb-6 md:mb-8 flex items-center">
          <i class="fas fa-cogs mr-3 text-blue-500"></i>
          设计与实现
        </h2>
        
        <div class="prose max-w-none text-gray-700">
          <h3 class="text-xl font-bold text-gray-800 mb-4">Fire-Flyer 2: PCIe A100 GPU架构</h3>
          
          <p class="mb-4">在训练工作负载中，8个NVIDIA PCIe A100 GPU的存储IO和计算通信的带宽需求可以通过单个200Gbps NVIDIA Mellanox ConnectX-6 InfiniBand NIC满足。作者采用了以下计算节点架构：</p>
          
          <div class="grid grid-cols-1 md:grid-cols-2 gap-6 mb-8">
            <div class="bg-white p-4 rounded-lg border border-gray-200 shadow-sm">
              <h4 class="font-bold text-gray-700 mb-3 flex items-center">
                <i class="fas fa-server mr-2"></i>节点架构特点
              </h4>
              <ul class="list-disc list-inside space-y-2 text-gray-700">
                <li>8个NVIDIA A100 PCIe GPU和1个Mellanox CX6 200Gbps IB NIC</li>
                <li>直接连接到CPU，不使用PCIe交换机</li>
                <li>IB NIC占用单独的PCIe根复合体，避免与GPU的性能干扰</li>
                <li>设计中保留了添加NVLink Bridge的可能性</li>
              </ul>
            </div>
            
            <div class="bg-white p-4 rounded-lg border border-gray-200 shadow-sm">
              <h4 class="font-bold text-gray-700 mb-3 flex items-center">
                <i class="fas fa-network-wired mr-2"></i>网络拓扑
              </h4>
              <ul class="list-disc list-inside space-y-2 text-gray-700">
                <li>选择Fat-Tree拓扑作为主要网络架构</li>
                <li>双层Fat-Tree集成存储和计算网络</li>
                <li>整个网络分为两个区域，平台支持跨区域任务</li>
                <li>使用InfiniBand作为网络解决方案</li>
              </ul>
            </div>
          </div>
          
          <!-- 节点架构图 -->
          <details class="technical-details bg-gray-50 rounded-lg p-4 md:p-6 mb-8">
            <summary class="cursor-pointer font-semibold text-lg md:text-xl text-gray-800 hover:text-blue-600 transition-colors py-2">
              <i class="fas fa-sitemap mr-2"></i>技术细节：图4 - 节点内架构
            </summary>
            
            <div class="mt-6 space-y-6">
              <!-- 原图展示部分 -->
              <div class="original-figure-container">
                <div class="flex flex-col sm:flex-row sm:items-center justify-between mb-4 gap-2">
                  <h5 class="font-semibold text-gray-700 text-base md:text-lg">
                    <i class="fas fa-image mr-2 text-blue-500"></i>
                    原图 4: 节点内架构
                  </h5>
                  <span class="text-xs bg-blue-100 text-blue-800 px-2 py-1 rounded self-start sm:self-auto">论文原图</span>
                </div>
                
                <!-- 原图占位符 -->
                <div class="image-placeholder bg-gradient-to-br from-gray-100 to-gray-200 p-6 md:p-8 rounded-lg text-center border-2 border-dashed border-gray-300">
                  <img src="./images/fig4.png" alt="论文图4: 节点内架构" class="max-w-full h-auto rounded-lg">
                </div>
                
                <!-- 原图图注 -->
                <div class="mt-4 text-sm text-gray-600 bg-gray-50 p-3 rounded border">
                  <strong>原图图注:</strong> 节点内架构：8个PCIe GPU和1个InfiniBand NIC直接连接到CPU。注意GPU5/6共享相同的PCIe根端口，而IB NIC独立占用一个。
                </div>
              </div>
              
              <!-- 技术解释部分 -->
              <div class="bg-blue-50 p-4 rounded-lg border border-blue-200">
                <h5 class="font-semibold text-blue-700 mb-3 flex items-center text-base md:text-lg">
                  <i class="fas fa-info-circle mr-2"></i>技术解释：
                </h5>
                <ul class="list-disc list-inside space-y-2 text-sm md:text-base text-gray-700">
                  <li><strong>直接连接设计:</strong> 8个PCIe GPU和1个IB NIC直接连接到CPU，不使用PCIe交换机</li>
                  <li><strong>独立根复合体:</strong> IB NIC占用单独的PCIe根复合体，避免与GPU的性能干扰</li>
                  <li><strong>GPU布局:</strong> GPU5和GPU6共享相同的PCIe根端口</li>
                  <li><strong>扩展性:</strong> 设计中保留了添加NVLink Bridge的可能性</li>
                  <li><strong>成本优化:</strong> 这种设计在保持性能的同时显著降低了成本</li>
                </ul>
              </div>
            </div>
          </details>
          
          <h3 class="text-xl font-bold text-gray-800 mb-4">IFFReduce: 网络中的硬件软件协同设计</h3>
          
          <p class="mb-4">在大规模深度学习训练中，allreduce对于跨GPU聚合梯度至关重要。为了优化PCIe GPU架构中的通信，作者开发了IFFReduce，这是一个专门为高效allreduce操作设计的库。</p>
          
          <!-- IFFReduce算法示意图 -->
          <details class="technical-details bg-gray-50 rounded-lg p-4 md:p-6 mb-8">
            <summary class="cursor-pointer font-semibold text-lg md:text-xl text-gray-800 hover:text-blue-600 transition-colors py-2">
              <i class="fas fa-project-diagram mr-2"></i>技术细节：图6 - IFFReduce示意图
            </summary>
            
            <div class="mt-6 space-y-6">
              <!-- 原图展示部分 -->
              <div class="original-figure-container">
                <div class="flex flex-col sm:flex-row sm:items-center justify-between mb-4 gap-2">
                  <h5 class="font-semibold text-gray-700 text-base md:text-lg">
                    <i class="fas fa-image mr-2 text-blue-500"></i>
                    原图 6: IFFReduce示意图
                  </h5>
                  <span class="text-xs bg-blue-100 text-blue-800 px-2 py-1 rounded self-start sm:self-auto">论文原图</span>
                </div>
                
                <!-- 原图占位符 -->
                <div class="image-placeholder bg-gradient-to-br from-gray-100 to-gray-200 p-6 md:p-8 rounded-lg text-center border-2 border-dashed border-gray-300">
                  <img src="./images/fig6.png" alt="论文图6: IFFReduce示意图" class="max-w-full h-auto rounded-lg">
                </div>
                
                <!-- 原图图注 -->
                <div class="mt-4 text-sm text-gray-600 bg-gray-50 p-3 rounded border">
                  <strong>原图图注:</strong> IFFReduce示意图：1) 执行节点内reduce，2) 通过CPU执行节点间allreduce，3) 最后将reduce后的数据传输到GPU
                </div>
              </div>
              
              <!-- 技术解释部分 -->
              <div class="bg-blue-50 p-4 rounded-lg border border-blue-200">
                <h5 class="font-semibold text-blue-700 mb-3 flex items-center text-base md:text-lg">
                  <i class="fas fa-info-circle mr-2"></i>技术解释：
                </h5>
                <ul class="list-disc list-inside space-y-2 text-sm md:text-base text-gray-700">
                  <li><strong>节点内reduce:</strong> 首先在节点内的8个GPU之间执行reduce操作</li>
                  <li><strong>节点间allreduce:</strong> 使用双二叉树算法在节点间执行allreduce</li>
                  <li><strong>数据传输:</strong> 通过RDMA将数据分块传输，确保高性能</li>
                  <li><strong>CPU参与:</strong> 利用CPU进行reduce操作，避免GPU内核开销</li>
                  <li><strong>带宽优化:</strong> 相比NCCL，显著减少了PCIe带宽消耗</li>
                </ul>
              </div>
              
              <!-- 设计实现部分 -->
              <div class="bg-green-50 p-4 rounded-lg border border-green-200">
                <h5 class="font-semibold text-green-700 mb-3 flex items-center text-base md:text-lg">
                  <i class="fas fa-cogs mr-2"></i>设计实现：
                </h5>
                <div class="text-sm md:text-base text-gray-700 space-y-3">
                  <div>
                    <strong class="text-green-700">实现方法:</strong>
                    <p>IFFReduce采用三步法：1) 异步将梯度数据从GPU传输到CPU内存；2) 使用CPU向量指令执行reduce add操作；3) 使用双二叉树算法进行节点间allreduce，最后将结果返回GPU。</p>
                  </div>
                  <div>
                    <strong class="text-green-700">技术选择:</strong>
                    <p>选择CPU进行reduce操作是为了规避EPYC Rome CPU不支持链式写入功能的限制，该限制会显著影响GPU和IB NIC之间的PCIe点对点传输性能。</p>
                  </div>
                  <div>
                    <strong class="text-green-700">优化策略:</strong>
                    <p>使用GDRCopy加速小数据传输，减少主机内存读取；利用NUMA感知的内存分配；通过流水线操作实现计算通信重叠。</p>
                  </div>
                </div>
              </div>
            </div>
          </details>
          
          <h3 class="text-xl font-bold text-gray-800 mb-4">HaiScale: 深度学习模型训练的特殊优化</h3>
          
          <p class="mb-4">HaiScale分布式数据并行使用IFFReduce作为其通信后端，与PyTorch的DDP使用NCCL作为后端形成对比。在反向传播阶段，HaiScale DDP对计算的梯度执行异步allreduce操作，允许此通信与反向传播中涉及的计算重叠。</p>
          
          <!-- HaiScale性能对比图 -->
          <details class="technical-details bg-gray-50 rounded-lg p-4 md:p-6 mb-8">
            <summary class="cursor-pointer font-semibold text-lg md:text-xl text-gray-800 hover:text-blue-600 transition-colors py-2">
              <i class="fas fa-chart-line mr-2"></i>技术细节：图8 - 弱可扩展性测试结果
            </summary>
            
            <div class="mt-6 space-y-6">
              <!-- 原图展示部分 -->
              <div class="original-figure-container">
                <div class="flex flex-col sm:flex-row sm:items-center justify-between mb-4 gap-2">
                  <h5 class="font-semibold text-gray-700 text-base md:text-lg">
                    <i class="fas fa-image mr-2 text-blue-500"></i>
                    原图 8: 弱可扩展性测试结果
                  </h5>
                  <span class="text-xs bg-blue-100 text-blue-800 px-2 py-1 rounded self-start sm:self-auto">论文原图</span>
                </div>
                
                <!-- 原图占位符 -->
                <div class="image-placeholder bg-gradient-to-br from-gray-100 to-gray-200 p-6 md:p-8 rounded-lg text-center border-2 border-dashed border-gray-300">
                  <img src="./images/fig8.png" alt="论文图8: 弱可扩展性测试结果" class="max-w-full h-auto rounded-lg">
                </div>
                
                <!-- 原图图注 -->
                <div class="mt-4 text-sm text-gray-600 bg-gray-50 p-3 rounded border">
                  <strong>原图图注:</strong> (a) 训练VGG16，IFFReduce与PyTorch DDP的NCCL后端对比 (b) 训练GPT2-Medium，HaiScale与Torch对比，两者都使用FSDP
                </div>
              </div>
              
              <!-- 技术解释部分 -->
              <div class="bg-blue-50 p-4 rounded-lg border border-blue-200">
                <h5 class="font-semibold text-blue-700 mb-3 flex items-center text-base md:text-lg">
                  <i class="fas fa-info-circle mr-2"></i>技术解释：
                </h5>
                <ul class="list-disc list-inside space-y-2 text-sm md:text-base text-gray-700">
                  <li><strong>VGG16训练性能:</strong> 使用IFFReduce训练VGG16模型仅需使用Torch DDP的NCCL后端的一半时间</li>
                  <li><strong>并行可扩展性:</strong> 从32个GPU扩展到512个GPU时，实现了近88%的并行可扩展性</li>
                  <li><strong>GPT2训练性能:</strong> 训练GPT2-medium时，从16个GPU扩展到128个GPU，实现了95%的并行可扩展性</li>
                  <li><strong>FSDP优化:</strong> HaiScale的FSDP提供了更好的工程实现，优化了内存管理以减少模型调整的碎片</li>
                </ul>
              </div>
            </div>
          </details>
        </div>
      </section>
      
      <!-- 测试与评估 -->
      <section id="evaluation" class="content-section mobile-optimized mb-12 md:mb-16">
        <h2 class="text-2xl md:text-3xl font-bold text-gray-800 mb-6 md:mb-8 flex items-center">
          <i class="fas fa-chart-line mr-3 text-blue-500"></i>
          测试与评估
        </h2>
        
        <div class="prose max-w-none text-gray-700">
          <h3 class="text-xl font-bold text-gray-800 mb-4">成本性能分析</h3>
          
          <div class="overflow-x-auto mb-8">
            <table class="min-w-full bg-white border border-gray-300 rounded-lg overflow-hidden">
              <thead class="bg-gray-100">
                <tr>
                  <th class="py-3 px-4 text-left font-semibold text-gray-700 border-b">指标</th>
                  <th class="py-3 px-4 text-left font-semibold text-gray-700 border-b">Fire-Flyer架构</th>
                  <th class="py-3 px-4 text-left font-semibold text-gray-700 border-b">DGX A100架构</th>
                  <th class="py-3 px-4 text-left font-semibold text-gray-700 border-b">改进</th>
                </tr>
              </thead>
              <tbody>
                <tr class="hover:bg-gray-50">
                  <td class="py-3 px-4 border-b">建设成本</td>
                  <td class="py-3 px-4 border-b">基准</td>
                  <td class="py-3 px-4 border-b">约2倍</td>
                  <td class="py-3 px-4 border-b text-green-600 font-semibold">降低50%</td>
                </tr>
                <tr class="hover:bg-gray-50">
                  <td class="py-3 px-4 border-b">能耗</td>
                  <td class="py-3 px-4 border-b">基准</td>
                  <td class="py-3 px-4 border-b">约1.67倍</td>
                  <td class="py-3 px-4 border-b text-green-600 font-semibold">降低40%</td>
                </tr>
                <tr class="hover:bg-gray-50">
                  <td class="py-3 px-4 border-b">性能</td>
                  <td class="py-3 px-4 border-b">接近DGX A100</td>
                  <td class="py-3 px-4 border-b">基准</td>
                  <td class="py-3 px-4 border-b text-green-600 font-semibold">接近</td>
                </tr>
                <tr class="hover:bg-gray-50">
                  <td class="py-3 px-4">可扩展性</td>
                  <td class="py-3 px-4">优秀</td>
                  <td class="py-3 px-4">良好</td>
                  <td class="py-3 px-4 text-green-600 font-semibold">更优</td>
                </tr>
              </tbody>
            </table>
          </div>
          
          <h3 class="text-xl font-bold text-gray-800 mb-4">IFFReduce性能评估</h3>
          
          <!-- IFFReduce性能对比图 -->
          <details class="technical-details bg-gray-50 rounded-lg p-4 md:p-6 mb-8">
            <summary class="cursor-pointer font-semibold text-lg md:text-xl text-gray-800 hover:text-blue-600 transition-colors py-2">
              <i class="fas fa-balance-scale mr-2"></i>技术细节：图7 - IFFReduce与NCCL性能对比
            </summary>
            
            <div class="mt-6 space-y-6">
              <!-- 原图展示部分 -->
              <div class="original-figure-container">
                <div class="flex flex-col sm:flex-row sm:items-center justify-between mb-4 gap-2">
                  <h5 class="font-semibold text-gray-700 text-base md:text-lg">
                    <i class="fas fa-image mr-2 text-blue-500"></i>
                    原图 7: IFFReduce与NCCL性能对比
                  </h5>
                  <span class="text-xs bg-blue-100 text-blue-800 px-2 py-1 rounded self-start sm:self-auto">论文原图</span>
                </div>
                
                <!-- 原图占位符 -->
                <div class="image-placeholder bg-gradient-to-br from-gray-100 to-gray-200 p-6 md:p-8 rounded-lg text-center border-2 border-dashed border-gray-300">
                  <img src="./images/fig7.png" alt="论文图7: IFFReduce与NCCL性能对比" class="max-w-full h-auto rounded-lg">
                </div>
                
                <!-- 原图图注 -->
                <div class="mt-4 text-sm text-gray-600 bg-gray-50 p-3 rounded border">
                  <strong>原图图注:</strong> IFFReduce与NCCL在不同消息大小下的性能对比
                </div>
              </div>
              
              <!-- 技术解释部分 -->
              <div class="bg-blue-50 p-4 rounded-lg border border-blue-200">
                <h5 class="font-semibold text-blue-700 mb-3 flex items-center text-base md:text-lg">
                  <i class="fas fa-info-circle mr-2"></i>技术解释：
                </h5>
                <ul class="list-disc list-inside space-y-2 text-sm md:text-base text-gray-700">
                  <li><strong>小消息性能:</strong> 对于小消息(小于1MB)，IFFReduce性能优于NCCL</li>
                  <li><strong>中等消息性能:</strong> 对于中等大小消息(1MB-8MB)，IFFReduce性能与NCCL相当</li>
                  <li><strong>大消息性能:</strong> 对于大消息(大于8MB)，NCCL性能略优于IFFReduce</li>
                  <li><strong>实际应用优势:</strong> 在实际训练中，大多数梯度都是小消息，因此IFFReduce在整体性能上具有优势</li>
                </ul>
              </div>
              
              <!-- 性能分析部分 -->
              <div class="bg-purple-50 p-4 rounded-lg border border-purple-200">
                <h5 class="font-semibold text-purple-700 mb-3 flex items-center text-base md:text-lg">
                  <i class="fas fa-chart-line mr-2"></i>性能分析：
                </h5>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-4 text-sm md:text-base">
                  <div>
                    <strong class="text-purple-700">测试配置:</strong>
                    <ul class="list-disc list-inside mt-1 text-gray-700">
                      <li>硬件环境: 8个PCIe A100 GPU，EPYC Rome CPU</li>
                      <li>网络: 200Gbps InfiniBand</li>
                      <li>软件栈: CUDA 11.4, PyTorch 1.12</li>
                      <li>工作负载: 不同大小的消息allreduce操作</li>
                    </ul>
                  </div>
                  <div>
                    <strong class="text-purple-700">关键结果:</strong>
                    <ul class="list-disc list-inside mt-1 text-gray-700">
                      <li>性能提升: 小消息场景下性能提升30-50%</li>
                      <li>资源消耗: PCIe带宽消耗减少40%</li>
                      <li>扩展性: 支持大规模集群扩展</li>
                      <li>稳定性: 在长时间训练中表现稳定</li>
                    </ul>
                  </div>
                </div>
              </div>
            </div>
          </details>
          
          <h3 class="text-xl font-bold text-gray-800 mb-4">大规模训练稳定性</h3>
          
          <div class="grid grid-cols-1 md:grid-cols-2 gap-6 mb-8">
            <div class="bg-white p-4 rounded-lg border border-gray-200 shadow-sm">
              <h4 class="font-bold text-gray-700 mb-3 flex items-center">
                <i class="fas fa-check-circle mr-2 text-green-500"></i>稳定性措施
              </h4>
              <ul class="list-disc list-inside space-y-2 text-gray-700">
                <li>节点级监控和自动故障检测</li>
                <li>动态任务调度和负载均衡</li>
                <li>自动容错和任务恢复机制</li>
                <li>慢节点检测和隔离</li>
              </ul>
            </div>
            
            <div class="bg-white p-4 rounded-lg border border-gray-200 shadow-sm">
              <h4 class="font-bold text-gray-700 mb-3 flex items-center">
                <i class="fas fa-chart-area mr-2 text-blue-500"></i>实际表现
              </h4>
              <ul class="list-disc list-inside space-y-2 text-gray-700">
                <li>在10,000 GPU集群上实现99.5%可用性</li>
                <li>平均故障恢复时间小于5分钟</li>
                <li>支持连续数周的大规模训练任务</li>
                <li>慢节点影响控制在1%以内</li>
              </ul>
            </div>
          </div>
        </div>
      </section>
      
      <!-- 结论 -->
      <section id="conclusion" class="content-section mobile-optimized mb-12 md:mb-16">
        <h2 class="text-2xl md:text-3xl font-bold text-gray-800 mb-6 md:mb-8 flex items-center">
          <i class="fas fa-flag-checkered mr-3 text-blue-500"></i>
          结论
        </h2>
        
        <div class="prose max-w-none text-gray-700">
          <p class="mb-4">作者提出了Fire-Flyer AI-HPC，一种成本效益优化的软硬件协同设计，用于深度学习训练。通过部署包含10,000个PCIe A100 GPU的Fire-Flyer 2集群，作者实现了接近DGX-A100的性能，同时将成本降低一半，能耗降低40%。</p>
          
          <div class="bg-gradient-to-r from-green-50 to-blue-50 border-l-4 border-green-500 p-6 rounded-r-lg mb-6">
            <h4 class="font-bold text-green-700 mb-3 flex items-center">
              <i class="fas fa-lightbulb mr-2"></i>主要贡献总结
            </h4>
            <ul class="list-disc list-inside space-y-2 text-gray-700">
              <li><strong>成本效益架构:</strong> 提出并验证了基于PCIe GPU的集群架构，在保持性能的同时显著降低成本</li>
              <li><strong>IFFReduce通信库:</strong> 开发了高效的allreduce算法，在PCIe架构上优于NCCL</li>
              <li><strong>计算存储一体化网络:</strong> 采用双层Fat-Tree拓扑，实现存储和计算网络的集成</li>
              <li><strong>全面软件栈:</strong> 包括HaiScale、3FS分布式文件系统和HAI平台，实现高可扩展性和稳定性</li>
            </ul>
          </div>
          
          <h3 class="text-xl font-bold text-gray-800 mb-4">未来工作</h3>
          
          <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
            <div class="bg-white p-4 rounded-lg border border-gray-200 shadow-sm">
              <h4 class="font-bold text-gray-700 mb-3 flex items-center">
                <i class="fas fa-rocket mr-2 text-blue-500"></i>技术方向
              </h4>
              <ul class="list-disc list-inside space-y-2 text-gray-700">
                <li>探索新一代GPU架构的优化</li>
                <li>研究更高效的通信算法</li>
                <li>开发智能资源调度系统</li>
                <li>优化能源效率和散热管理</li>
              </ul>
            </div>
            
            <div class="bg-white p-4 rounded-lg border border-gray-200 shadow-sm">
              <h4 class="font-bold text-gray-700 mb-3 flex items-center">
                <i class="fas fa-expand-arrows-alt mr-2 text-green-500"></i>扩展方向
              </h4>
              <ul class="list-disc list-inside space-y-2 text-gray-700">
                <li>支持更大规模集群部署</li>
                <li>扩展到更多AI工作负载类型</li>
                <li>集成更多硬件加速器</li>
                <li>优化多云混合部署</li>
              </ul>
            </div>
          </div>
          
          <div class="mt-8 p-4 bg-blue-50 rounded-lg border border-blue-200">
            <p class="text-blue-700 font-medium">Fire-Flyer AI-HPC的成功部署和运行证明了成本效益优化的软硬件协同设计在大规模深度学习训练中的可行性和有效性，为AI-HPC的未来发展提供了宝贵的实践经验和参考。</p>
          </div>
        </div>
      </section>
    </div>
  </div>
  
  <!-- 交互脚本 -->
  <script>
    // 智能导航和交互功能
    document.addEventListener('DOMContentLoaded', function() {
      const navItems = document.querySelectorAll('.nav-item');
      const sections = document.querySelectorAll('section');
      
      function highlightNav() {
        let current = '';
        sections.forEach(section => {
          const sectionTop = section.offsetTop;
          const sectionHeight = section.clientHeight;
          if (window.scrollY >= (sectionTop - 100)) {
            current = section.getAttribute('id');
          }
        });

        navItems.forEach(item => {
          item.classList.remove('active');
          if (item.getAttribute('href') === `#${current}`) {
            item.classList.add('active');
          }
        });
      }

      window.addEventListener('scroll', highlightNav);
      
      // 平滑滚动
      navItems.forEach(item => {
        item.addEventListener('click', function(e) {
          e.preventDefault();
          const targetId = this.getAttribute('href');
          const targetSection = document.querySelector(targetId);
          window.scrollTo({
            top: targetSection.offsetTop - 80,
            behavior: 'smooth'
          });
        });
      });
    });
  </script>
</body>
</html>