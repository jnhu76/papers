[
  {
    "id": "9b5f5c6c8c2f",
    "title": "Scalable Address Spaces using Concurrent Interval Skiplist",
    "authors": [
      "Kim, Tae Woo",
      "Kwon, Youngjin",
      "Kang, Jeehoon"
    ],
    "year": 2025,
    "conference": "SOSP '25",
    "category": "操作系统",
    "keywords": [
      "操作系统",
      "地址空间",
      "可扩展性",
      "并发数据结构",
      "内存管理",
      "并行操作",
      "区间跳表"
    ],
    "abstract": "A kernel's address space design can significantly bottleneck multi-threaded applications, as address space operations such as mmap() and mumap() are serialized by coarse-grained locks like Linux's mmap_lock. Such locks have long been known as one of the most intractable contention points in memory management. While prior works have attempted to address this issue, they either fail to sufficiently parallelize operations or are impractical for real-world kernels. We present the first scalable and practical address space design that parallelizes critical operations. We identify key scalability bottlenecks—many of which extend beyond address spaces—and address them with targeted solutions. At its core is the concurrent interval skiplist, a new data structure that integrates mapping and locking for parallel interval operations. We implement our design on Linux 6.8 and evaluate it on a dual-socket 48-core machine. Our results show a significant throughput improvement of 13.1× for an mmap() microbenchmark, 4.49× for LevelDB, 3.19× for the Apache web server, 1.47× for Metis MapReduce, and 1.27× for Psearchy text indexing.",
    "htmlFile": "papers/2025/9b5f5c6c8c2f/index.html"
  },
  {
    "id": "a8d6f8c4f2e3",
    "title": "Tiered Memory Management Beyond Hotness",
    "authors": [
      "Jinshu Liu",
      "Hamid Hadian",
      "Hanchen Xu",
      "Huaicheng Li"
    ],
    "year": 2025,
    "conference": "OSDI'19",
    "category": "操作系统与内存管理",
    "keywords": [
      "分层内存",
      "内存管理",
      "Amortized Offcore Latency (AOL)",
      "Memory-Level Parallelism (MLP)",
      "CXL内存",
      "页面迁移",
      "性能优化"
    ],
    "abstract": "Tiered memory systems often rely on access frequency (\"hotness\") to guide data placement. However, hot data is not always performance-critical, limiting the effectiveness of hotness-based policies. We introduce amortized offcore latency (AOL), a novel metric that precisely captures the true performance impact of memory accesses by accounting for memory access latency and memory-level parallelism (MLP). Leveraging AOL, we present two powerful tiering mechanisms: Soar, a profile-guided allocation policy that places objects based on their performance contribution, and Atro, a lightweight page migration regulation policy to eliminate unnecessary migrations. Soar and Atro outperform four state-of-the-art tiering designs across a diverse set of workloads by up to 12.4×, while underperforming in a few cases by no more than 3%.",
    "htmlFile": "papers/2025/a8d6f8c4f2e3/index.html"
  },
  {
    "id": "b4a1c8b4a1c8",
    "title": "How to Copy Memory? Coordinated Asynchronous Copy as a First-Class OS Service",
    "authors": [
      "Jingkai He",
      "Yunpeng Dong",
      "Dong Du",
      "Mo Zou",
      "Zhitai Yu",
      "Yuxin Ren",
      "Ning Jia",
      "Yubin Xia",
      "Haibo Chen"
    ],
    "year": 2025,
    "conference": "SOSP '25",
    "category": "操作系统",
    "keywords": [
      "内存复制",
      "异步复制",
      "操作系统服务",
      "操作系统",
      "内存管理",
      "性能优化",
      "硬件加速"
    ],
    "abstract": "In modern systems, memory copy remains a critical performance bottleneck across various scenarios, playing a pervasive role in system-wide execution such as syscalls, IPC, and user-mode applications. Numerous efforts have aimed at optimizing copy performance, including zero-copy with page remapping and hardware-accelerated copy. However, they typically target specific use cases, such as Linux zero-copy send() for messages of ≥10KB. This paper argues for copy as a first-class OS service, offering three key benefits: (1) with the asynchronous copy abstraction provided by the service, applications can overlap their execution with copy; (2) the service can effectively utilize hardware capabilities to enhance copy performance; (3) the service's global view of copies further enables holistic optimization. To this end, we introduce Copier, a new OS service of coordinated asynchronous copy, to serve both user-mode applications and OS services. We build Copier-Linux to demonstrate Copier's ability to improve performance for diverse use cases, including Redis, Protobuf, network stack, proxy, etc. Evaluations show that Copier achieves up to a 1.8× speedup for real-world applications like Redis and a 1.6× improvement over zIO, the state-of-the-art in optimizing copy efficiency. To further facilitate adoption, we develop a toolchain to ease the use of Copier. We also integrate Copier into a commercial smartphone OS (HarmonyOS 5.0), achieving promising results.",
    "htmlFile": "papers/2025/b4a1c8b4a1c8/index.html"
  },
  {
    "id": "b5c8a1d4f7e2",
    "title": "Prove It to the Kernel: Precise Extension Analysis via Proof-Guided Abstraction Refinement",
    "authors": [
      "Sun, Hao",
      "Su, Zhendong"
    ],
    "year": 2025,
    "conference": "SOSP '25",
    "category": "操作系统与系统软件",
    "keywords": [
      "eBPF验证",
      "抽象解释",
      "证明引导的抽象精化",
      "内核扩展",
      "静态分析",
      "形式化证明",
      "SMT求解"
    ],
    "abstract": "Modern OS kernels, such as Linux, employ the eBPF subsystem to enable user space to extend kernel functionality. To ensure safety, an in-kernel verifier statically analyzes these extensions; however, its imprecise analysis frequently results in the erroneous rejection of safe extensions, exposing a critical tension between the precision and computational complexity of the verifier that limits kernel extensibility.\n\nWe propose a proof-guided abstraction refinement technique that significantly enhances the verifier's precision while preserving low kernel space complexity. Rather than incorporating sophisticated analysis (e.g., via new abstract domains) directly into the verifier, our key insight is to decouple the complex reasoning to user space while bridging the gap through formal proofs. Upon encountering uncertainties, the verifier initiates an abstraction refinement procedure rather than rejecting the extension. As the refinement involves nontrivial reasoning, the verifier simply delineates the task and delegates it to user space. A formal proof is produced externally, which the verifier subsequently checks in linear time before adopting the refined abstraction. Consequently, our approach achieves high precision via user space reasoning while confining kernel space operations to an efficient proof check. Evaluation results show that our technique enables the verifier to accept 403 out of 512 real-world eBPF programs that were previously rejected erroneously, paving the way for more reliable and flexible kernel extensions.",
    "htmlFile": "papers/2025/b5c8a1d4f7e2/index.html"
  },
  {
    "id": "d6d3c8e8f2d2",
    "title": "Mantle: Efficient Hierarchical Metadata Management for Cloud Object Storage Services",
    "authors": [
      "Li, Jiahao",
      "Cao, Biao",
      "Jian, Jielong",
      "Li, Cheng",
      "Han, Sen",
      "Wang, Yiduo",
      "Wu, Yufei",
      "Chen, Kang",
      "Yin, Zhihui",
      "Chen, Qiushi",
      "Xiong, Jiwei",
      "Zhao, Jie",
      "Liu, Fengyuan",
      "Xing, Yan",
      "Duan, Liguo",
      "Yu, Miao",
      "Zheng, Ran",
      "Wu, Feng",
      "Meng, Xianjun"
    ],
    "year": 2025,
    "conference": "SOSP '25",
    "category": "分布式系统",
    "keywords": [
      "元数据管理",
      "云对象存储",
      "层次结构",
      "路径解析",
      "目录更新",
      "可扩展性",
      "性能优化"
    ],
    "abstract": "Cloud Object Storage Services (COSSs) are the primary storage backend in the cloud, supporting large-scale analytics and ML workloads that frequently access deep object paths and update metadata concurrently. However, current COSS architectures incur costly multi-round lookups and high directory contention, delaying job execution. Prior optimizations, largely designed for distributed file systems (with least adoption in clouds), do not apply due to COSS-specific constraints like stateless proxies and limited APIs. Mantle is a new COSS metadata service for modern cloud workloads. It adopts a two-layer architecture: a scalable, sharded database (TafDB) shared across namespaces and a per-namespace, single-server IndexMode consolidating lightweight directory metadata. With a fine-grained division of metadata and responsibility, Mantle supports up to 10 billion objects or directories in a single namespace and achieves 1.8 million lookups per second through scalable execution of single-RPC lookups on IndexMode. It also delivers up to 58K directory updates per second under high contention by integrating out-of-place delta updates in TafDB and offloading loop detection for cross-directory renames to IndexMode, both effectively eliminating coordination bottlenecks. Compared to the metadata services of Teetonic, InfiniFS and LocoFS, Mantle reduces metadata latency by 6.6-99.1% and improves throughput by 0.07-115.00%. With data access enabled, it shortens job completion times by 63.3-93.3% for interactive Spark analytics and 38.5-47.7% for AI-driven audio preprocessing tasks. Mantle has been deployed on Baidu Object Storage (BOS) for over 2 years, a service offered by Baidu Canghai Storage.",
    "htmlFile": "papers/2025/d6d3c8e8f2d2/index.html"
  },
  {
    "id": "d9c4a2e3b5f1",
    "title": "Moirai: Optimizing Placement of Data and Compute in Hybrid Clouds",
    "authors": [
      "Qiu, Ziyue",
      "Park, Hojin",
      "Zhao, Jing",
      "Wang, Yukai",
      "Balyan, Arnav",
      "Singh, Gurmeet",
      "Zhang, Yangjun",
      "Song, Suqiang (Jack)",
      "Ganger, Gregory R.",
      "Amvrosiadis, George"
    ],
    "year": 2025,
    "conference": "SOSP '25",
    "category": "分布式系统与云计算",
    "keywords": [
      "混合云",
      "成本优化",
      "数据布局",
      "作业调度",
      "网络开销",
      "数据复制",
      "作业路由"
    ],
    "abstract": "The deployment of large-scale data analytics between on-premise and cloud sites, i.e., hybrid clouds, requires careful partitioning of both data and computation to avoid massive networking costs. We present Moirai, a cost-optimization framework that analyzes job accesses and data dependencies and optimizes the placement of both in hybrid clouds. Moirai informs the job scheduler of data location and access predictions, so it can determine where jobs should be executed to minimize data transfer costs. Our optimizer achieves scalability and cost efficiency by exploiting recurring jobs to identify data dependencies and job access characteristics and reduces the search space by excluding data not accessed recently. We validate Moirai using 4-month traces that span 66.7M queries accessing 13.3EB from Presto and Spark clusters deployed at Uber, a multi-national transportation company leveraging large-scale data analytics for its operations. Moirai reduces hybrid cloud deployment costs by over 97% relative to the state-of-the-art partitioning approach from Alibaba and other public approaches. The savings come from 95–99.5% reduction in cloud egress, up to 99% reduction in replication, and 89–98% reduction in on-premises network infrastructure requirements. We also describe concrete steps being taken towards deploying Moirai in production.",
    "htmlFile": "papers/2025/d9c4a2e3b5f1/index.html"
  },
  {
    "id": "e9c6b3a8f4d2",
    "title": "TickTock: Verified Isolation in a Production Embedded OS",
    "authors": [
      "Rindisbacher, Vivien",
      "Johnson, Evan",
      "Pannuto, Pat",
      "Savage, Stefan"
    ],
    "year": 2025,
    "conference": "SOSP '25",
    "category": "操作系统安全",
    "keywords": [
      "验证",
      "进程隔离",
      "内核安全",
      "嵌入式系统",
      "安全系统",
      "精化类型",
      "形式化验证"
    ],
    "abstract": "We present a case study formally verifying process isolation in the Tock production microcontroller OS kernel. Tock combines hardware memory protection units and language-level techniques—by writing the kernel in Rust—to enforce isolation between user and kernel code. Our effort to verify Tock’s process abstraction unearthed multiple, subtle bugs that broke isolation—many allowing malicious applications to compromise the whole OS. We describe this effort and TickTock, our fork of the Tock operating system kernel that eliminates isolation bugs by construction. TickTock uses Flux, an SMT-based Rust verifier, to formally specify and verify process isolation for all ARMy7-M platforms Tock supports and for three RISC-V 32-bit platforms. Our verification-guided design and implementation led to a new, granular process abstraction that is simpler than Tock’s, has formal security guarantees (that are verified in half a minute), and outperforms Tock on certain critical code paths.",
    "htmlFile": "papers/2025/e9c6b3a8f4d2/index.html"
  }
]