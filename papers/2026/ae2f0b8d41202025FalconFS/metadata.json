{
    "id": "ae2f0b8d41202025FalconFS",
    "title": "FalconFS: Distributed File System for Large-Scale Deep Learning Pipeline",
    "authors": ["Jingwei Xu", "Junbin Kang", "Mingkai Dong", "Mingyu Liu", "Lu Zhang", "Shaohong Guo", "Ziyan Qiu", "Mingzhen You", "Ziyi Tian", "Anqi Yu", "Tianhong Ding", "Xinwei Hu", "Haibo Chen"],
    "year": 2026,
    "conference": "NSDI",
    "category": "分布式系统",
    "keywords": ["分布式文件系统", "deep learning", "metadata management", "client-stateless architecture", "path resolution", "FalconFS", "scalability"],
    "abstract": "Client-side metadata caching has long been considered an effective method for accelerating metadata operations in distributed file systems (DFSs). However, we have found that client-side state (e.g., caching) is not only ineffective but also consumes valuable memory resources in the deep learning pipelines. We thus propose FalconFS, a DFS optimized for deep learning pipelines with the stateless-client architecture. Specifically, instead of performing client-side path resolution and caching, FalconFS efficiently resolves paths on the server side using hybrid metadata indexing and lazy namespace replication. FalconFS also boosts server concurrency with concurrent request merging and provides easy deployment with VFS shortcut. Evaluations against CephFS and Lustre show that FalconFS achieves up to 5.72× throughput for small file read/write and up to 12.81× throughput for deep learning model training. FalconFS has been running in Huawei autonomous driving system's production environment with 10,000 NPUs for one year and has been open-sourced."
}