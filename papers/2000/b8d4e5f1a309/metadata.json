{
  "id": "b8d4e5f1a309",
  "title": "A comparison of file system workloads",
  "authors": ["Drew Roselli", "Jacob R. Lorch", "Thomas E. Anderson"],
  "year": 2000,
  "conference": "USENIX ATC",
  "category": "文件系统",
  "keywords": ["文件系统", "工作负载分析", "磁盘I/O", "内存映射", "缓存性能", "块生命周期", "访问模式"],
  "abstract": "In this paper, we describe the collection and analysis of file system traces from a variety of different environments, including both UNIX and NT systems, clients and servers, and instructional and production systems. Our goal is to understand how modern workloads affect the ability of file systems to provide high performance to users. Because of the increasing gap between processor speed and disk latency, file system performance is largely determined by its disk behavior. Therefore we primarily focus on the disk I/O aspects of the traces. We find that more processes access files via the memory-map interface than through the read interface. However, because many processes memory-map a small set of files, these files are likely to be cached. We also find that file access has a bimodal distribution pattern: some files are written repeatedly without being read; other files are almost exclusively read. We develop a new metric for measuring file lifetime that accounts for files that are never deleted. Using this metric, we find that the average block lifetime for some workloads is significantly longer than the 30-second write delay used by many file systems. However, all workloads show lifetime locality: the same files tend to be overwritten multiple times."
}