<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>DeepSeek-OCR: Contexts Optical Compression</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  <style>
    body { 
      font-family: 'Inter', sans-serif; 
      scroll-behavior: smooth;
    }
    .mobile-optimized { 
      margin-bottom: 2rem !important; 
    }
    @media (max-width: 768px) {
      .content-section { 
        padding: 1rem; 
        margin-bottom: 1.5rem;
      }
      .technical-details {
        margin: 1rem 0;
      }
    }
    .hide-scrollbar {
      -ms-overflow-style: none;
      scrollbar-width: none;
    }
    .hide-scrollbar::-webkit-scrollbar {
      display: none;
    }
    .nav-item {
      @apply px-4 py-2 rounded-lg transition-colors duration-200 text-gray-600 hover:text-blue-600 hover:bg-blue-50;
    }
    .nav-item.active {
      @apply text-blue-600 bg-blue-100;
    }
  </style>
</head>
<body class="bg-gradient-to-br from-blue-400 via-purple-500 to-pink-400 min-h-screen">
  <!-- 导航系统 -->
  <nav class="nav-scroll bg-white/90 backdrop-blur-sm sticky top-0 z-50 border-b border-gray-200">
    <div class="container mx-auto px-4 py-3">
      <div class="flex overflow-x-auto space-x-6 hide-scrollbar">
        <a href="#abstract" class="nav-item whitespace-nowrap">摘要</a>
        <a href="#background-motivation" class="nav-item whitespace-nowrap">背景与动机</a>
        <a href="#challenges" class="nav-item whitespace-nowrap">问题与挑战</a>
        <a href="#design-implementation" class="nav-item whitespace-nowrap">设计与实现</a>
        <a href="#evaluation" class="nav-item whitespace-nowrap">测试与评估</a>
        <a href="#conclusion" class="nav-item whitespace-nowrap">结论</a>
      </div>
    </div>
  </nav>

  <div class="container mx-auto px-4 py-8">
    <div class="bg-white/95 backdrop-blur-sm rounded-xl shadow-lg p-6">
      <!-- 论文标题和元数据 -->
      <div class="mb-12 md:mb-16">
        <h1 class="text-3xl md:text-4xl font-bold text-gray-800 mb-6 text-center md:text-left">
          DeepSeek-OCR: Contexts Optical Compression
        </h1>
        
        <div class="bg-gradient-to-r from-blue-50 to-purple-50 border-l-4 border-blue-500 p-6 rounded-r-lg">
          <div class="grid grid-cols-1 md:grid-cols-2 gap-4 text-gray-700">
            <div class="space-y-3">
              <div>
                <strong class="text-blue-700 block mb-1">作者信息</strong>
                <div class="text-lg">Haoran Wei, Yaofeng Sun, Yukun Li</div>
                <div class="text-sm text-gray-600 mt-1">DeepSeek-AI</div>
              </div>
              <div>
                <strong class="text-blue-700 block mb-1">代码与模型</strong>
                <div class="font-mono text-sm bg-white px-3 py-2 rounded border">http://github.com/deepseek-ai/DeepSeek-OCR</div>
              </div>
            </div>
            <div class="space-y-3">
              <div>
                <strong class="text-blue-700 block mb-1">关键词</strong>
                <div class="flex flex-wrap gap-2 mt-1">
                  <span class="bg-blue-100 text-blue-800 px-3 py-1 rounded-full text-sm">OCR</span>
                  <span class="bg-green-100 text-green-800 px-3 py-1 rounded-full text-sm">视觉压缩</span>
                  <span class="bg-purple-100 text-purple-800 px-3 py-1 rounded-full text-sm">多模态模型</span>
                  <span class="bg-yellow-100 text-yellow-800 px-3 py-1 rounded-full text-sm">长上下文处理</span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
      
      <!-- 核心贡献 -->
      <div class="bg-gradient-to-r from-green-50 to-blue-50 border-l-4 border-green-500 p-6 rounded-r-lg mb-12">
        <h4 class="font-bold text-green-700 mb-4 flex items-center text-xl">
          <i class="fas fa-trophy mr-2"></i>核心贡献
        </h4>
        <ul class="list-disc list-inside space-y-2 text-gray-700">
          <li>首次系统性地探索了视觉-文本压缩的边界，实现9-10倍压缩比下96%+的OCR精度</li>
          <li>提出DeepEncoder架构，在高分辨率输入下保持低激活内存和最小视觉token数量</li>
          <li>开发基于DeepSeek3B-MoE的DeepSeek-OCR模型，在OmniDocBench上实现SOTA性能</li>
          <li>展示了光学上下文压缩在长上下文处理和记忆遗忘机制中的潜力</li>
        </ul>
      </div>
      
      <!-- 摘要 -->
      <section id="abstract" class="content-section mobile-optimized mb-12 md:mb-16">
        <h2 class="text-2xl md:text-3xl font-bold text-gray-800 mb-6 md:mb-8 flex items-center">
          <i class="fas fa-file-alt mr-3 text-blue-500"></i>
          摘要
        </h2>
        <div class="prose max-w-none text-gray-700">
          <p class="mb-4">
            作者提出了DeepSeek-OCR作为通过光学2D映射压缩长上下文的可行性初步研究。DeepSeek-OCR包含两个组件：DeepEncoder和DeepSeek3B-MoE-A570M作为解码器。
          </p>
          <p class="mb-4">
            实验表明，当文本token数量在视觉token数量的10倍以内（即压缩比<10×）时，模型可以实现97%的解码（OCR）精度。即使在20×的压缩比下，OCR准确率仍保持在约60%。这显示了在历史长上下文压缩和LLM记忆遗忘机制等研究领域的巨大潜力。
          </p>
          <p>
            在生产环境中，DeepSeek-OCR可以以每天20万+页的规模（单张A100-40G）为LLMs/VLMs生成训练数据。
          </p>
        </div>
      </section>
      
      <!-- 背景与动机 -->
      <section id="background-motivation" class="content-section mobile-optimized mb-12 md:mb-16">
        <h2 class="text-2xl md:text-3xl font-bold text-gray-800 mb-6 md:mb-8 flex items-center">
          <i class="fas fa-layer-group mr-3 text-blue-500"></i>
          背景与动机
        </h2>
        <div class="prose max-w-none text-gray-700">
          <p class="mb-4">
            当前大型语言模型在处理长文本内容时面临显著的计算挑战，因为其计算复杂度与序列长度呈二次方增长。作者探索了一个潜在的解决方案：利用视觉模态作为文本信息的高效压缩媒介。
          </p>
          <p class="mb-4">
            包含文档文本的单个图像可以使用比等效数字文本少得多的token来表示丰富的信息，这表明通过视觉token进行光学压缩可以实现更高的压缩比。
          </p>
          <p class="mb-6">
            OCR任务作为连接视觉和语言的中间模态，为这种视觉-文本压缩范式提供了理想的测试平台，因为它们在视觉和文本表示之间建立了自然的压缩-解压缩映射，同时提供了定量评估指标。
          </p>
          
          <div class="bg-yellow-50 p-4 rounded-lg border border-yellow-200 mb-6">
            <h5 class="font-semibold text-yellow-700 mb-2 flex items-center">
              <i class="fas fa-lightbulb mr-2"></i>研究动机
            </h5>
            <p class="text-gray-700">
              重新从以LLM为中心的视角审视视觉语言模型，关注视觉编码器如何提高LLM处理文本信息的效率，而不是人类擅长的基本VQA任务。
            </p>
          </div>
        </div>
      </section>
      
      <!-- 问题与挑战 -->
      <section id="challenges" class="content-section mobile-optimized mb-12 md:mb-16">
        <h2 class="text-2xl md:text-3xl font-bold text-gray-800 mb-6 md:mb-8 flex items-center">
          <i class="fas fa-exclamation-triangle mr-3 text-blue-500"></i>
          问题与挑战
        </h2>
        <div class="prose max-w-none text-gray-700">
          <p class="mb-4">
            当前开源VLM使用的视觉编码器存在多种限制，无法完全满足高效视觉-文本压缩的需求：
          </p>
          
          <div class="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6">
            <div class="bg-red-50 p-4 rounded-lg border border-red-200">
              <h5 class="font-semibold text-red-700 mb-3 flex items-center">
                <i class="fas fa-times-circle mr-2"></i>双塔架构 (Vary)
              </h5>
              <ul class="list-disc list-inside space-y-1 text-sm text-gray-700">
                <li>需要双重图像预处理</li>
                <li>部署复杂</li>
                <li>训练时编码器流水线并行困难</li>
              </ul>
            </div>
            
            <div class="bg-orange-50 p-4 rounded-lg border border-orange-200">
              <h5 class="font-semibold text-orange-700 mb-3 flex items-center">
                <i class="fas fa-puzzle-piece mr-2"></i>分块方法 (InternVL2.0)
              </h5>
              <ul class="list-disc list-inside space-y-1 text-sm text-gray-700">
                <li>原生编码器分辨率低</li>
                <li>大图像过度碎片化</li>
                <li>产生大量视觉token</li>
              </ul>
            </div>
            
            <div class="bg-purple-50 p-4 rounded-lg border border-purple-200">
              <h5 class="font-semibold text-purple-700 mb-3 flex items-center">
                <i class="fas fa-expand-alt mr-2"></i>自适应分辨率 (Qwen2-VL)
              </h5>
              <ul class="list-disc list-inside space-y-1 text-sm text-gray-700">
                <li>大图像激活内存消耗大</li>
                <li>可能导致GPU内存溢出</li>
                <li>训练时需要极长序列长度</li>
              </ul>
            </div>
            
            <div class="bg-blue-50 p-4 rounded-lg border border-blue-200">
              <h5 class="font-semibold text-blue-700 mb-3 flex items-center">
                <i class="fas fa-question-circle mr-2"></i>关键研究问题
              </h5>
              <p class="text-sm text-gray-700">
                对于包含1000个单词的文档，解码至少需要多少个视觉token？这个问题对于"一图胜千言"原理的研究具有重要意义。
              </p>
            </div>
          </div>
        </div>
      </section>
      
      <!-- 设计与实现 -->
      <section id="design-implementation" class="content-section mobile-optimized mb-12 md:mb-16">
        <h2 class="text-2xl md:text-3xl font-bold text-gray-800 mb-6 md:mb-8 flex items-center">
          <i class="fas fa-cogs mr-3 text-blue-500"></i>
          设计与实现
        </h2>
        
        <!-- 系统架构 -->
        <div class="mb-8">
          <h3 class="text-xl font-bold text-gray-800 mb-4 flex items-center">
            <i class="fas fa-sitemap mr-2 text-blue-500"></i>
            系统架构
          </h3>
          
          <div class="original-figure-container bg-white p-4 rounded-lg border border-gray-200 shadow-sm mb-6">
            <div class="flex items-center justify-between mb-3">
              <h5 class="font-semibold text-gray-700">
                <i class="fas fa-image mr-2 text-blue-500"></i>
                原图 3: DeepSeek-OCR架构
              </h5>
              <span class="text-xs bg-blue-100 text-blue-800 px-2 py-1 rounded">论文原图</span>
            </div>
            
            <div class="image-placeholder bg-gradient-to-br from-gray-100 to-gray-200 p-8 rounded-lg text-center border-2 border-dashed border-gray-300">
              <img src="./images/fig3.png" alt="DeepSeek-OCR架构图，包含DeepEncoder和DeepSeek-3B-MoE解码器" class="max-w-full h-auto rounded-lg">
            </div>
            
            <div class="mt-3 text-sm text-gray-600 bg-gray-50 p-3 rounded border">
              <strong>原图图注:</strong> DeepSeek-OCR由DeepEncoder和DeepSeek-3B-MoE解码器组成。DeepEncoder是DeepSeek-OCR的核心，包含三个组件：用于感知的SAM（主导窗口注意力）、用于知识的CLIP（密集全局注意力）以及连接它们的16×token压缩器。
            </div>
          </div>
          
          <div class="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6">
            <div class="bg-blue-50 p-4 rounded-lg border border-blue-200">
              <h5 class="font-semibold text-blue-700 mb-3 flex items-center">
                <i class="fas fa-encode mr-2"></i>DeepEncoder
              </h5>
              <ul class="list-disc list-inside space-y-1 text-sm text-gray-700">
                <li>参数量：约380M</li>
                <li>组成：80M SAM-base + 300M CLIP-large</li>
                <li>核心：16×卷积压缩器</li>
                <li>支持多分辨率输入</li>
              </ul>
            </div>
            
            <div class="bg-green-50 p-4 rounded-lg border border-green-200">
              <h5 class="font-semibold text-green-700 mb-3 flex items-center">
                <i class="fas fa-decode mr-2"></i>MoE解码器
              </h5>
              <ul class="list-disc list-inside space-y-1 text-sm text-gray-700">
                <li>架构：DeepSeek-3B-MoE</li>
                <li>激活参数：约570M</li>
                <li>专家路由：6/64 + 2共享专家</li>
                <li>推理效率：500M小模型级别</li>
              </ul>
            </div>
          </div>
        </div>
        
        <!-- DeepEncoder技术细节 -->
        <details class="technical-details bg-gray-50 rounded-lg p-4 md:p-6 mb-8">
          <summary class="cursor-pointer font-semibold text-lg md:text-xl text-gray-800 hover:text-blue-600 transition-colors py-2">
            <i class="fas fa-microscope mr-2"></i>技术细节：DeepEncoder架构
          </summary>
          
          <div class="mt-6 space-y-6">
            <!-- 技术解释部分 -->
            <div class="bg-blue-50 p-4 rounded-lg border border-blue-200">
              <h5 class="font-semibold text-blue-700 mb-3 flex items-center text-base md:text-lg">
                <i class="fas fa-info-circle mr-2"></i>技术解释：
              </h5>
              <ul class="list-disc list-inside space-y-2 text-sm md:text-base text-gray-700">
                <li><strong>双组件设计:</strong> 窗口注意力主导的视觉感知特征提取组件 + 密集全局注意力的视觉知识特征提取组件</li>
                <li><strong>16×压缩:</strong> 通过2层卷积模块实现16倍下采样，将4096个token压缩为256个</li>
                <li><strong>内存优化:</strong> 窗口注意力组件处理大量视觉token，压缩后进入全局注意力组件，实现内存和token的有效压缩</li>
                <li><strong>预训练收益:</strong> 利用SAM-base和CLIP-large的预训练优势</li>
              </ul>
            </div>
            
            <!-- 多分辨率支持 -->
            <div class="bg-green-50 p-4 rounded-lg border border-green-200">
              <h5 class="font-semibold text-green-700 mb-3 flex items-center text-base md:text-lg">
                <i class="fas fa-cogs mr-2"></i>多分辨率支持：
              </h5>
              <div class="text-sm md:text-base text-gray-700 space-y-3">
                <div>
                  <strong class="text-green-700">原生分辨率模式:</strong>
                  <div class="grid grid-cols-2 md:grid-cols-4 gap-2 mt-2">
                    <div class="text-center bg-white p-2 rounded border">
                      <div class="font-bold">Tiny</div>
                      <div class="text-xs">512×512 (64 tokens)</div>
                    </div>
                    <div class="text-center bg-white p-2 rounded border">
                      <div class="font-bold">Small</div>
                      <div class="text-xs">640×640 (100 tokens)</div>
                    </div>
                    <div class="text-center bg-white p-2 rounded border">
                      <div class="font-bold">Base</div>
                      <div class="text-xs">1024×1024 (256 tokens)</div>
                    </div>
                    <div class="text-center bg-white p-2 rounded border">
                      <div class="font-bold">Large</div>
                      <div class="text-xs">1280×1280 (400 tokens)</div>
                    </div>
                  </div>
                </div>
                <div>
                  <strong class="text-green-700">动态分辨率模式:</strong>
                  <p>Gundam模式：n×640×640局部视图 + 1024×1024全局视图，输出token数：n×100+256</p>
                </div>
              </div>
            </div>
          </div>
        </details>
        
        <!-- 数据引擎 -->
        <div class="mb-8">
          <h3 class="text-xl font-bold text-gray-800 mb-4 flex items-center">
            <i class="fas fa-database mr-2 text-blue-500"></i>
            数据引擎
          </h3>
          
          <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-4">
            <div class="bg-blue-50 p-4 rounded-lg border border-blue-200">
              <h5 class="font-semibold text-blue-700 mb-2">OCR 1.0数据 (70%)</h5>
              <ul class="text-sm text-gray-700 space-y-1">
                <li>• 30M页PDF文档</li>
                <li>• 100种语言支持</li>
                <li>• 中英文各25M页</li>
                <li>• 场景图像OCR</li>
              </ul>
            </div>
            
            <div class="bg-green-50 p-4 rounded-lg border border-green-200">
              <h5 class="font-semibold text-green-700 mb-2">OCR 2.0数据</h5>
              <ul class="text-sm text-gray-700 space-y-1">
                <li>• 10M图表数据</li>
                <li>• 5M化学公式</li>
                <li>• 1M平面几何</li>
                <li>• 复杂人工图像解析</li>
              </ul>
            </div>
            
            <div class="bg-purple-50 p-4 rounded-lg border border-purple-200">
              <h5 class="font-semibold text-purple-700 mb-2">通用视觉数据 (20%)</h5>
              <ul class="text-sm text-gray-700 space-y-1">
                <li>• 图像描述</li>
                <li>• 目标检测</li>
                <li>• 定位任务</li>
                <li>• 保留通用视觉接口</li>
              </ul>
            </div>
            
            <div class="bg-yellow-50 p-4 rounded-lg border border-yellow-200">
              <h5 class="font-semibold text-yellow-700 mb-2">纯文本数据 (10%)</h5>
              <ul class="text-sm text-gray-700 space-y-1">
                <li>• 内部预训练数据</li>
                <li>• 序列长度8192 tokens</li>
                <li>• 保持语言能力</li>
              </ul>
            </div>
          </div>
        </div>
      </section>
      
      <!-- 测试与评估 -->
      <section id="evaluation" class="content-section mobile-optimized mb-12 md:mb-16">
        <h2 class="text-2xl md:text-3xl font-bold text-gray-800 mb-6 md:mb-8 flex items-center">
          <i class="fas fa-chart-line mr-3 text-blue-500"></i>
          测试与评估
        </h2>
        
        <!-- 视觉-文本压缩研究 -->
        <div class="mb-8">
          <h3 class="text-xl font-bold text-gray-800 mb-4 flex items-center">
            <i class="fas fa-compress-alt mr-2 text-blue-500"></i>
            视觉-文本压缩研究
          </h3>
          
          <div class="original-figure-container bg-white p-4 rounded-lg border border-gray-200 shadow-sm mb-6">
            <div class="flex items-center justify-between mb-3">
              <h5 class="font-semibold text-gray-700">
                <i class="fas fa-image mr-2 text-blue-500"></i>
                原图 1(a): 压缩比测试结果
              </h5>
              <span class="text-xs bg-blue-100 text-blue-800 px-2 py-1 rounded">论文原图</span>
            </div>
            
            <div class="image-placeholder bg-gradient-to-br from-gray-100 to-gray-200 p-8 rounded-lg text-center border-2 border-dashed border-gray-300">
              <img src="./images/fig1a.png" alt="Fox基准测试上的压缩比结果，显示不同压缩比下的OCR精度" class="max-w-full h-auto rounded-lg">
            </div>
            
            <div class="mt-3 text-sm text-gray-600 bg-gray-50 p-3 rounded border">
              <strong>原图图注:</strong> 在Fox基准测试上的压缩比（真实文本token数量/模型使用的视觉token数量）测试结果。
            </div>
          </div>
          
          <div class="overflow-x-auto mb-6">
            <table class="min-w-full bg-white border border-gray-200 rounded-lg">
              <thead class="bg-gray-50">
                <tr>
                  <th class="px-4 py-2 border-b text-left">文本Token范围</th>
                  <th class="px-4 py-2 border-b text-center" colspan="2">视觉Token=64</th>
                  <th class="px-4 py-2 border-b text-center" colspan="2">视觉Token=100</th>
                  <th class="px-4 py-2 border-b text-center">页数</th>
                </tr>
                <tr>
                  <th></th>
                  <th class="px-4 py-2 border-b text-center">精度</th>
                  <th class="px-4 py-2 border-b text-center">压缩比</th>
                  <th class="px-4 py-2 border-b text-center">精度</th>
                  <th class="px-4 py-2 border-b text-center">压缩比</th>
                  <th class="px-4 py-2 border-b text-center"></th>
                </tr>
              </thead>
              <tbody>
                <tr class="hover:bg-gray-50">
                  <td class="px-4 py-2 border-b">600-700</td>
                  <td class="px-4 py-2 border-b text-center">96.5%</td>
                  <td class="px-4 py-2 border-b text-center">10.5×</td>
                  <td class="px-4 py-2 border-b text-center">98.5%</td>
                  <td class="px-4 py-2 border-b text-center">6.7×</td>
                  <td class="px-4 py-2 border-b text-center">7</td>
                </tr>
                <tr class="hover:bg-gray-50">
                  <td class="px-4 py-2 border-b">700-800</td>
                  <td class="px-4 py-2 border-b text-center">93.8%</td>
                  <td class="px-4 py-2 border-b text-center">11.8×</td>
                  <td class="px-4 py-2 border-b text-center">97.3%</td>
                  <td class="px-4 py-2 border-b text-center">7.5×</td>
                  <td class="px-4 py-2 border-b text-center">28</td>
                </tr>
                <tr class="hover:bg-gray-50">
                  <td class="px-4 py-2 border-b">800-900</td>
                  <td class="px-4 py-2 border-b text-center">83.8%</td>
                  <td class="px-4 py-2 border-b text-center">13.2×</td>
                  <td class="px-4 py-2 border-b text-center">96.8%</td>
                  <td class="px-4 py-2 border-b text-center">8.5×</td>
                  <td class="px-4 py-2 border-b text-center">28</td>
                </tr>
                <tr class="hover:bg-gray-50">
                  <td class="px-4 py-2 border-b">900-1000</td>
                  <td class="px-4 py-2 border-b text-center">85.9%</td>
                  <td class="px-4 py-2 border-b text-center">15.1×</td>
                  <td class="px-4 py-2 border-b text-center">96.8%</td>
                  <td class="px-4 py-2 border-b text-center">9.7×</td>
                  <td class="px-4 py-2 border-b text-center">14</td>
                </tr>
                <tr class="hover:bg-gray-50">
                  <td class="px-4 py-2 border-b">1000-1100</td>
                  <td class="px-4 py-2 border-b text-center">79.3%</td>
                  <td class="px-4 py-2 border-b text-center">16.5×</td>
                  <td class="px-4 py-2 border-b text-center">91.5%</td>
                  <td class="px-4 py-2 border-b text-center">10.6×</td>
                  <td class="px-4 py-2 border-b text-center">11</td>
                </tr>
                <tr class="hover:bg-gray-50">
                  <td class="px-4 py-2 border-b">1100-1200</td>
                  <td class="px-4 py-2 border-b text-center">76.4%</td>
                  <td class="px-4 py-2 border-b text-center">17.7×</td>
                  <td class="px-4 py-2 border-b text-center">89.8%</td>
                  <td class="px-4 py-2 border-b text-center">11.3×</td>
                  <td class="px-4 py-2 border-b text-center">8</td>
                </tr>
                <tr class="hover:bg-gray-50">
                  <td class="px-4 py-2 border-b">1200-1300</td>
                  <td class="px-4 py-2 border-b text-center">59.1%</td>
                  <td class="px-4 py-2 border-b text-center">19.7×</td>
                  <td class="px-4 py-2 border-b text-center">87.1%</td>
                  <td class="px-4 py-2 border-b text-center">12.6×</td>
                  <td class="px-4 py-2 border-b text-center">4</td>
                </tr>
              </tbody>
            </table>
          </div>
          
          <div class="bg-green-50 p-4 rounded-lg border border-green-200">
            <h5 class="font-semibold text-green-700 mb-2 flex items-center">
              <i class="fas fa-chart-bar mr-2"></i>关键发现
            </h5>
            <ul class="list-disc list-inside space-y-1 text-gray-700">
              <li><strong>10×压缩比内:</strong> 模型解码精度可达约97%，接近无损压缩</li>
              <li><strong>10-12×压缩比:</strong> 精度保持在~90%</li>
              <li><strong>20×压缩比:</strong> 精度仍接近60%，展示了光学上下文压缩的巨大潜力</li>
              <li><strong>无额外开销:</strong> 可利用现有VLM基础设施，多模态系统本身需要额外的视觉编码器</li>
            </ul>
          </div>
        </div>
        
        <!-- OCR实际性能 -->
        <div class="mb-8">
          <h3 class="text-xl font-bold text-gray-800 mb-4 flex items-center">
            <i class="fas fa-tachometer-alt mr-2 text-blue-500"></i>
            OCR实际性能
          </h3>
          
          <div class="original-figure-container bg-white p-4 rounded-lg border border-gray-200 shadow-sm mb-6">
            <div class="flex items-center justify-between mb-3">
              <h5 class="font-semibold text-gray-700">
                <i class="fas fa-image mr-2 text-blue-500"></i>
                原图 1(b): OmniDocBench性能对比
              </h5>
              <span class="text-xs bg-blue-100 text-blue-800 px-2 py-1 rounded">论文原图</span>
            </div>
            
            <div class="image-placeholder bg-gradient-to-br from-gray-100 to-gray-200 p-8 rounded-lg text-center border-2 border-dashed border-gray-300">
              <img src="./images/fig1b.png" alt="OmniDocBench上的性能对比，显示DeepSeek-OCR在端到端模型中达到SOTA性能" class="max-w-full h-auto rounded-lg">
            </div>
            
            <div class="mt-3 text-sm text-gray-600 bg-gray-50 p-3 rounded border">
              <strong>原图图注:</strong> 在OmniDocBench上的性能对比。DeepSeek-OCR可以在使用最少视觉token的端到端模型中实现最先进的性能。
            </div>
          </div>
          
          <div class="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6">
            <div class="bg-blue-50 p-4 rounded-lg border border-blue-200">
              <h5 class="font-semibold text-blue-700 mb-3">性能亮点</h5>
              <ul class="list-disc list-inside space-y-2 text-sm text-gray-700">
                <li><strong>仅100视觉token:</strong> 超越使用256 token的GOT-OCR2.0</li>
                <li><strong>400视觉token:</strong> 与当前SOTA模型性能相当</li>
                <li><strong>少于800 token:</strong> 超越平均使用7000+ token的MinerU2.0</li>
                <li><strong>更高token压缩:</strong> 具有更高的研究上限</li>
              </ul>
            </div>
            
            <div class="bg-purple-50 p-4 rounded-lg border border-purple-200">
              <h5 class="font-semibold text-purple-700 mb-3">实际应用价值</h5>
              <ul class="list-disc list-inside space-y-2 text-sm text-gray-700">
                <li><strong>大规模数据生成:</strong> 每天可处理20万+页面</li>
                <li><strong>高效训练:</strong> 单张A100-40G GPU</li>
                <li><strong>多语言支持:</strong> 支持近100种语言</li>
                <li><strong>生产就绪:</strong> 强大的实际应用能力</li>
              </ul>
            </div>
          </div>
        </div>
        
        <!-- 定性研究 -->
        <div class="mb-8">
          <h3 class="text-xl font-bold text-gray-800 mb-4 flex items-center">
            <i class="fas fa-search-plus mr-2 text-blue-500"></i>
            定性研究
          </h3>
          
          <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mb-6">
            <div class="bg-blue-50 p-4 rounded-lg border border-blue-200">
              <h5 class="font-semibold text-blue-700 mb-3 flex items-center">
                <i class="fas fa-sitemap mr-2"></i>深度解析
              </h5>
              <p class="text-sm text-gray-700">
                具备布局和OCR 2.0能力，可通过二次模型调用进一步解析文档中的图像，包括图表、几何图形、化学公式和自然图像。
              </p>
            </div>
            
            <div class="bg-green-50 p-4 rounded-lg border border-green-200">
              <h5 class="font-semibold text-green-700 mb-3 flex items-center">
                <i class="fas fa-globe mr-2"></i>多语言识别
              </h5>
              <p class="text-sm text-gray-700">
                支持近100种语言，包括阿拉伯语、僧伽罗语等，支持布局和非布局OCR格式输出。
              </p>
            </div>
            
            <div class="bg-purple-50 p-4 rounded-lg border border-purple-200">
              <h5 class="font-semibold text-purple-700 mb-3 flex items-center">
                <i class="fas fa-eye mr-2"></i>通用视觉理解
              </h5>
              <p class="text-sm text-gray-700">
                保留通用视觉理解能力，包括图像描述、目标检测、定位等任务，同时保持语言能力。
              </p>
            </div>
          </div>
        </div>
      </section>
      
      <!-- 结论 -->
      <section id="conclusion" class="content-section mobile-optimized mb-12 md:mb-16">
        <h2 class="text-2xl md:text-3xl font-bold text-gray-800 mb-6 md:mb-8 flex items-center">
          <i class="fas fa-flag-checkered mr-3 text-blue-500"></i>
          结论
        </h2>
        
        <div class="prose max-w-none text-gray-700">
          <div class="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6">
            <div class="bg-blue-50 p-4 rounded-lg border border-blue-200">
              <h5 class="font-semibold text-blue-700 mb-3 flex items-center">
                <i class="fas fa-check-circle mr-2"></i>主要贡献
              </h5>
              <ul class="list-disc list-inside space-y-2 text-sm text-gray-700">
                <li>首次系统性地探索了视觉-文本压缩的边界</li>
                <li>提出DeepEncoder架构，在高分辨率输入下保持低激活内存</li>
                <li>开发基于DeepSeek3B-MoE的DeepSeek-OCR模型</li>
                <li>在OmniDocBench上实现SOTA性能</li>
                <li>展示了光学上下文压缩在长上下文处理中的潜力</li>
              </ul>
            </div>
            
            <div class="bg-green-50 p-4 rounded-lg border border-green-200">
              <h5 class="font-semibold text-green-700 mb-3 flex items-center">
                <i class="fas fa-chart-line mr-2"></i>性能总结
              </h5>
              <ul class="list-disc list-inside space-y-2 text-sm text-gray-700">
                <li><strong>9-10×压缩比:</strong> 96%+ OCR精度</li>
                <li><strong>20×压缩比:</strong> 约60% OCR精度</li>
                <li><strong>生产规模:</strong> 每天20万+页面处理能力</li>
                <li><strong>多语言支持:</strong> 近100种语言</li>
              </ul>
            </div>
          </div>
          
          <div class="bg-yellow-50 p-4 rounded-lg border border-yellow-200 mb-6">
            <h5 class="font-semibold text-yellow-700 mb-3 flex items-center">
              <i class="fas fa-road mr-2"></i>未来研究方向
            </h5>
            <ul class="list-disc list-inside space-y-2 text-sm text-gray-700">
              <li><strong>历史长上下文压缩:</strong> 将历史对话和文档压缩为视觉token</li>
              <li><strong>LLM记忆遗忘机制:</strong> 通过压缩实现选择性记忆</li>
              <li><strong>多模态压缩:</strong> 探索其他模态的压缩可能性</li>
              <li><strong>压缩算法优化:</strong> 进一步提高压缩比和精度</li>
            </ul>
          </div>
          
          <p class="text-gray-700">
            作者的研究表明，通过视觉模态进行文本压缩具有巨大的潜力，特别是在长上下文处理和记忆管理方面。DeepSeek-OCR不仅在实际OCR任务中表现出色，更重要的是为理解视觉-文本压缩的边界提供了重要的实证基础。
          </p>
        </div>
      </section>
    </div>
  </div>
  
  <!-- 交互脚本 -->
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      const navItems = document.querySelectorAll('.nav-item');
      const sections = document.querySelectorAll('section');
      
      function highlightNav() {
        let current = '';
        sections.forEach(section => {
          const sectionTop = section.offsetTop;
          const sectionHeight = section.clientHeight;
          if (window.scrollY >= (sectionTop - 100)) {
            current = section.getAttribute('id');
          }
        });

        navItems.forEach(item => {
          item.classList.remove('active');
          if (item.getAttribute('href') === `#${current}`) {
            item.classList.add('active');
          }
        });
      }

      window.addEventListener('scroll', highlightNav);
      
      // 平滑滚动
      navItems.forEach(item => {
        item.addEventListener('click', function(e) {
          e.preventDefault();
          const targetId = this.getAttribute('href');
          const targetSection = document.querySelector(targetId);
          window.scrollTo({
            top: targetSection.offsetTop - 80,
            behavior: 'smooth'
          });
        });
      });
      
      // 初始化导航高亮
      highlightNav();
    });
  </script>
<!-- AI生成内容标识 -->\n<div id="ai-badge" style="position: fixed; bottom: 20px; right: 20px; z-index: 9999; cursor: pointer;"><div style="background: linear-gradient(135deg, #6366f1, #8b5cf6); color: white; padding: 8px 16px; border-radius: 20px; font-size: 14px; font-weight: 600; box-shadow: 0 4px 12px rgba(99, 102, 241, 0.3); display: flex; align-items: center; gap: 6px; transition: all 0.3s ease;"><span style="font-size: 16px;">🤖</span><span>AI生成</span></div></div><script>(function(){const badge=document.getElementById('ai-badge');let expanded=false; badge.addEventListener('click',function(){if(!expanded){const details=document.createElement('div');details.id='ai-details';details.style.cssText="position:absolute;bottom:50px;right:0;background:white;color:#333;padding:12px;border-radius:8px;box-shadow:0 4px 12px rgba(0,0,0,0.15);width:200px;font-size:12px;line-height:1.5;border:1px solid #e5e7eb;";details.innerHTML='<div style="font-weight:600;margin-bottom:8px;color:#6366f1">人工智能生成内容</div><div style="color:#666">本页面内容通过AI技术自动生成，仅供参考。生成时间：'+new Date().toLocaleDateString('zh-CN')+'</div>';badge.appendChild(details);expanded=true;}else{const details=document.getElementById('ai-details');if(details)details.remove();expanded=false;}});})();</script>\n</body>
</html>