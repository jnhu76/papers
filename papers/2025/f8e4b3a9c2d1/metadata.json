{
  "id": "f8e4b3a9c2d1",
  "title": "FalconFS: Distributed File System for Large-Scale Deep Learning Pipeline",
  "authors": ["Jingwei Xu", "Junbin Kang", "Mingkai Dong", "Mingyu Liu", "Lu Zhang", "Shaohong Guo", "Ziyan Qiu", "Mingzhen You", "Ziyi Tian", "Anqi Yu", "Tianhong Ding", "Xinwei Hu", "Haibo Chen"],
  "year": 2025,
  "conference": "arXiv",
  "category": "分布式系统",
  "keywords": ["分布式文件系统", "深度学习", "元数据管理", "无状态客户端", "高性能存储"],
  "abstract": "Client-side metadata caching has long been considered an effective method for accelerating metadata operations in distributed file systems(DFSs). However, we have found thatclient-side state(e.g., caching) is not only ineffective but alsoconsumes valuable memory resources in the deep learning pipelines. We thus propose FalconFS, a DFS optimized for deep learning pipelines with the stateless-client architecture.Specifically, instead of performing client-side path resolution and caching, FalconFS efficiently resolves paths on the serverside using hybrid metadata indexing and lazy namespace replication. FalconFS also boosts server concurrency with concurrent request merging and provides easy deployment with VFS shortcut. Evaluations against CephFS and Lustreshow that FalconFS achievesup to 5.72× throughput for smallfile read/write and up to 12.81× throughput for deep learn-ing model training. FalconFS has been running in Huawei autonomous driving system’s production environment with10,000 NPUs for one year."
}