{
  "id": "a7c3e9b2f1d8",
  "title": "The FastLanes File Format",
  "authors": ["Azim Afroozeh", "Peter Boncz"],
  "year": 2025,
  "conference": "PVLDB",
  "category": "数据库系统",
  "keywords": ["文件格式", "轻量级压缩", "数据并行", "多列压缩", "向量化解码", "FastLanes", "Expression Encoding"],
  "abstract": "This paper introduces a new open-source big data file format, called FastLanes. It is designed for modern data-parallel execution (SIMD or GPU), and evolves the features of previous data formats such as Parquet, which are the foundation of data lakes, and which increasingly are used in AI pipelines. It does so by avoiding generic compression methods (e.g. Snappy) in favor of lightweight encodings, that are fully data-parallel. To enhance compression ratio, it cascades encodings using a flexible _expression encoding_ mechanism. This mechanism also enables multi-column compression (MCC), enhancing compression by exploiting correlations between columns, a long-time weakness of columnar storage. We contribute a 2-phase algorithm to find encodings expressions during compression.\n\nFastLanes also innovates in its API, providing flexible support for _partial_ decompression, facilitating engines to execute queries on compressed data. FastLanes is designed for fine-grained access, at the level of small batches rather than rowgroups; in order to limit the decompression memory footprint to fit CPU and GPU caches.\n\nWe contribute an open-source implementation of FastLanes in portable (auto-vectorizing) C++. Our evaluation on a corpus of real-world data shows that FastLanes improves compression ratio over Parquet, while strongly accelerating decompression, making it a win-win over the state-of-the-art."
}